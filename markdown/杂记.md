# 杂记

### Mybatis使用

~~~xml
Mybatis使用：

1. pom.xml文件加mysql和mybatis依赖：
<dependencies>
    <dependency>
        <groupId>mysql</groupId>
        <artifactId>mysql-connector-java</artifactId>
        <version>5.1.31</version>
    </dependency>

    <dependency>
        <groupId>org.mybatis</groupId>
        <artifactId>mybatis</artifactId>
        <version>3.1.1</version>
    </dependency>
</dependencies>

2. resource下新建mybatis_config.xml
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE configuration PUBLIC "-//mybatis.org//DTD Config 3.0//EN" "http://mybatis.org/dtd/mybatis-3-config.dtd">
<configuration>
    <environments default="development">
        <environment id="development">
            <transactionManager type="JDBC" />
            <!-- 配置数据库连接信息 -->
            <dataSource type="POOLED">
                <property name="driver" value="com.mysql.jdbc.Driver" />
                <property name="url" value="jdbc:mysql://localhost:3306/jfinal_demo?characterEncoding=utf8" />
                <property name="username" value="root" />
                <property name="password" value="12345678" />
            </dataSource>
        </environment>
    </environments>

    <mappers>
        <mapper resource="com/leo/UserMapper.xml"/>
    </mappers>

</configuration>

3. resource下进行com/leo/UserMapper.xml
<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd">
<mapper namespace="com.leo.UserMapper">

    <!--
        根据id查询得到一个user对象
     -->
    <select id="getUser" parameterType="int"
            resultType="com.leo.User">
        select * from user where id=#{id}
    </select>
</mapper>

4. 新建src/main/java/com/leo/User.java文件，定义PO对象User
5. 新建src/main/java/com/leo/UserMapper.java文件，定义User操作接口
6. 新建测试Main.java

run-error：Caused by: java.lang.NullPointerException
	at com.mysql.jdbc.ConnectionImpl.getServerCharacterEncoding
原因：mysql driver: 5.1.31 问题
升级 mysql driver to 5.1.44，OK

~~~

### 前端

> JavaScript runtime environment： Node.js
> package manager：npm
> package.json管理依赖包版本：语法：~ 与 ^
>
> ~~~
> {
>  "devDependencies": {
>    "ember-cli": "~1.0.1"
>  }
> }
> ~~~
>
> ~~~
> major.minor.patch
> 1.0.2
> ~~~
>
> npm uses the tilde (~) and caret (^) to designate which patch and minor versions to use respectively.
>
> So if you see `~1.0.2` it means to install version `1.0.2` or the latest patch version such as `1.0.4`. If you see `^1.0.2` it means to install version `1.0.2` or the latest minor or patch version such as `1.1.0`.
>
> TypeScript语法：https://www.tslang.cn/docs/home.html
>
> tsconfig.json：添加TypeScript文件的编译选项等
>
> JavaScript语法：https://www.liaoxuefeng.com/wiki/001434446689867b27157e896e74d51a89c25cc8b43bdb3000
>
> UI库：primeng
>
> 【查看npm镜像源: npm config get registry】
> 【设置npm镜像源: npm config set registry url】
>
> angular 应用打包部署:
> npm install -g @angular/cli （安装ng）
> ng build --output-path=release/ --configuration=test (package.json + environments/environment.test.ts)

### Java 泛型方法与可变参数的bug

~~~
java 泛型方法与可变参数的bug：反编译查看类型转换的错误

    public static void main(String[] args) {
        test ( arg() );
    }

    public static void test(Object... args) {
        System.out.println ( args );
    }

    public static <T> T arg() {
        return (T) "df";
    }
    
    反编译后的代码：
    
    public static void main(String[] args) {
        test ((Object[]) arg() ); //此处会报类型转换的错
    }

    public static void test(Object... args) {
        System.out.println ( args );
    }:

    public static Object arg() {
        return "df";
    }
   
  翻墙：
wget --no-check-certificate https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocks-all.sh
chmod +x shadowsocks-all.sh
./shadowsocks-all.sh 2>&1 | tee shadowsocks-all.log
~~~

### spring-security

~~~
浏览器同源(协议+域名+端口)政策： http://www.ruanyifeng.com/blog/2016/04/same-origin-policy.html
浏览器同源政策限制了：不同源的请求
1. cookie和LocalStorage不能共享
2. DOM无法获取
3. AJAX请求不能发送

同源政策规定，AJAX请求只能发给同源的网址，否则就报错。规避这个限制的方法有三种：
1. JSONP：利用javascript脚本可以跨源
2. WebSocket：该协议不实行同源政策，只要服务器支持，就可以通过它进行跨源通信
3. CORS：W3C标准，它允许浏览器向跨源服务器，发出XMLHttpRequest请求

cors: Cross-Origin Resource Sharing，是跨源AJAX请求的根本解决方法
关键点：浏览器在跨域请求里带上Origin字段；服务器响应带上Access-Control-Allow-Origin字段

xss: Cross-Site Scripting，跨域脚本攻击
攻击方式：在允许用户输入输出的地方插入恶意javascript
预防：对输入输出参数都需要进行过滤转义

SQL注入: 通过操作输入来修改后台SQL语句达到代码执行进行攻击目的的技术
攻击方式：通过在输入参数里加入SQL代码，比如where字句传入恒等表达式
预防：对参数进行过滤和转义

CRSF: Cross Site Request Forgery, 跨域请求伪造。攻击者盗用了你的身份，以你的名义发送恶意请求。

为什么会有CSRF?
JavaScript控制浏览器发送请求的时候，浏览器是根据目标站点，而不是来源站点，来发送cookie的，如果当前会话中有目标站点的cookie，就发送出去。核心问题是浏览器的会话机制，是跨站请求伪造漏洞的根源。

一次CRSF攻击：
1. 登录受信任网站A，并在本地生成Cookie。
2. 在不登出A的情况下，访问危险网站B。（攻击方式分get、post方式）

防范方法：CSRF攻击之所以能够成功，是因为攻击者可以伪造用户的请求，该请求中所有的用户验证信息都存在于Cookie中，因此攻击者可以在不知道这些验证信息的情况下直接利用用户自己的Cookie来通过安全验证。由此可知，抵御CSRF攻击的关键在于：在请求中放入攻击者所不能伪造的信息，并且该信息不存在于Cookie之中。

1. 加入token
2. 敏感操作使用post请求，防止token暴露在url中
3. 使用http协议的refer值，检测发起请求的网址是否合法
~~~

### Http状态码

101 - Switching Protocols

200 - OK

301 - 重定向

4xx -  客户端错误 (404 - Not Found / 403 - Forbidden / 400 - Bad Request / 401 - Unauthorized)

5xx - 服务器错误 (500 - Internal Server Error / 502 - Bad Gateway / 503 - Service Unavailable / 504 - Gateway Time-out)

### WEB登录认证

> > 1. http协议提供的认证方式 - BASIC 认证，不安全，不灵活，几乎不用
> > 2. http协议提供的认证方式 - DIGEST认证，相对安全，不灵活，也几乎不用
> > 3. http协议提供的认证方式 - SSL客户端证书，安全，收费，也几乎不用
> > 4. 基于表单的认证 - 没有共同的标准规范，实现各异，安全性各异，多使用此方式
>
>
>
> 参考： http://ayuliao.com/2017/11/18/浅谈Cookie、Session和JWT三种用户认证方式/
>
> 1. cookie
> 2. session
> 3. token - 加密加盐
>
> 参考：https://www.jianshu.com/p/613c615b7ef1 单点登录实现
>
>



### XML 解析

1. 编写xml schema文档，规定xml的书写规范
2. 编写xml文档
3. 解析xml（期间会根据xml schema来验证xml文档是否符合规范）



### Base64编码

> https://zh.wikipedia.org/wiki/Base64 
>
> Base64编码不是加密，不需要任何附加信息即可对其解码。
>
> 将文本数据转换成64个可打印字符来表示的方法，由于![{\displaystyle 2^{6}=64}](https://wikimedia.org/api/rest_v1/media/math/render/svg/c4becc8d811901597b9807eccff60f0897e3701a)，所以每6个bit为一个单元。
>
> 转换的时候，将3字节的数据，先后放入一个24bit的缓冲区中，先来的字节占高位。数据不足3字节的话，于缓冲区中剩下的bit用0补足。每次取出6bit（因为![{\displaystyle 2^{6}=64}](https://wikimedia.org/api/rest_v1/media/math/render/svg/c4becc8d811901597b9807eccff60f0897e3701a)），按照其值选择`ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/`中的字符作为编码后的输出，直到全部输入数据转换完成。



### 加密算法

1. MD5（Message-Digest Algorithm 5th，一种密码hash函数）

   应用：对一段信息（Message）产生信息摘要（Message-Digest），以防止被篡改。

   典型应用：下载软件时，都有提供一个md5值，下载完成后在本地进行md5验证以确保下载的软件是正确的。

2. SHA256（Secure Hash Algorithm - 256bit，一种密码hash函数）

   应用：对一段信息（Message）产生信息摘要（Message-Digest），以防止被篡改。

   典型应用：同MD5，但比MD5的破解难度更大，更安全。

3. HMAC （Hash-based Message Authentication Code：H代表所采用的hash算法如MD5，SHA256等）

   应用：以一个密钥和一个消息为输入，生成一个消息摘要作为输出。用于身份认证。

   典型应用：

   (1) 客户端发出登录请求（假设是浏览器的GET请求）

   (2) 服务器返回一个随机值，并在会话中记录这个随机值

   (3) 客户端将该随机值作为密钥，和用户密码进行hmac运算，然后提交给服务器

   (4) 服务器读取用户数据库中的用户密码和步骤2中发送的随机值做与客户端一样的hmac运算，然后与用户发送的结果比较，如果结果一致则验证用户合法

4. DES（一种对称加密算法[加密解密时使用同一个密钥]）

   应用：

   (1) 加密（key[密钥] + data[待加密数据] + mode[加密]）

   (2) 解密（key[密钥] + data[待解密数据] + mode[解密]）

5. RSA（一种非对称加密算法 [公钥密钥]）

   应用：对少量数据进行加密（因为加密速度很慢）

   典型应用1：加密解密 （此时：**公钥负责加密，私钥负责解密**）

   （1）乙方生成两把密钥（公钥和私钥）。公钥是公开的，任何人都可以获得，私钥则是保密的。

   （2）甲方获取乙方的公钥，然后用它对信息加密。

   （3）乙方得到加密后的信息，用私钥解密。

   典型应用2：数字签名（此时：**私钥负责签名，公钥负责验证**）

   （1）发送方先产生成一对密钥，并将公钥公开给接收方；

   （2）发送方将数据D用MD5/SHA/HMAC等进行消息摘要，得到Q；

   （3）用私钥对Q进行加密（签名）得到密文MQ，然后将数据D和密文MQ一起发送给接收方；

   （4）接收方得到数据D和密文MQ后，用公钥将密文MQ解密（验证）得到Q1；

   （5）接收方使用相同的算法对数据D进行消息摘要，得到Q2；

   （6）比较Q1和Q2，相等则证明D是由发送方发送的，且没有被修改过。

### HTTPS

> https 使用混合加密方式（非对称加密和对称加密）：
>
> 1. web服务器使用非对称加密生成公钥和密钥，然后将公钥发布出去
>
>    【公钥的发布：使用第三方机构颁发的数字证书，具体步骤如下：
>
>    1. 第三方机构自己的公钥已事先内置在客户端浏览器里
>    2. 第三方机构用自己的密钥对web服务器的公钥进行数字签名（具体方法见RSA典型应用2）
>    3. 客户端使用第三方机构的公钥验证web服务器的数字证书上的数字签名，确定web服务器发来的公钥的真实性
>    4. 走以下步骤2】
>
> 2. 客户端使用公钥加密**密匙**【后面对http消息使用对称加密的密匙】，发送给web服务器
>
> 3. 客户端使用**密匙**对http消息进行加密，然后将加密后对消息发送给web服务器
>
> 4. web服务器使用**密匙**对收到的http消息进行解密



### docker mysql

```terminal
docker pull mysql/mysql-server:latest
docker run --name=mysql1 -p 3306:3306 -d mysql/mysql-server:latest
docker ps
docker logs mysql1 2>&1 | grep GENERATED
docker exec -it mysql1 mysql -uroot -p
mysql> ALTER USER 'root'@'localhost' IDENTIFIED BY '12345678';
mysql> update mysql.user set host='%' where user='root';
mysql> ALTER USER 'root'@'%' IDENTIFIED BY '12345678';
mysql> GRANT ALL ON *.* TO 'root'@'%';
mysql> flush privileges;
docker exec -it mysql1 bash 
bash-4.2# yum install vim
docker commit mysql1
docker stop mysql1
docker start mysql1
docker restart mysql1

//java 连接docker mysql报错：
//Unable to load authentication plugin 'caching_sha2_password'.
docker exec -it mysql1 mysql -uroot -p
mysql> ALTER USER 'root'@'%' IDENTIFIED WITH mysql_native_password BY '12345678';
docker commit mysql1
docker restart mysql1

//保存修改到镜像，会创建新的镜像且依赖于旧镜像，导致旧镜像无法删除
docker commit mysql1 mysql/mysql-server
//查看所有依赖镜像
docker inspect --format='{{.Id}} {{.Parent}}' $(docker images --filter since=a02eab9e2434 --quiet)
//保存最新镜像到文件
docker save -o mysql-server.tar mysql/mysql-server:latest
//删除所有依赖镜像
docker rmi a02eab9e2434 
...
//导入tar文件生成新镜像
docker load -i ./mysql-server.tar
//从新镜像run容器，并查看之前的commit在不在
docker run --name=mysql1 -p 3306:3306 -d mysql/mysql-server:latest
//草，bash里通过命令安装的vim在，mysql的配置和表table不在


```

### docker redis

~~~
1. 关闭mac 宿主机上启动的redis-server
ps aux | grep redis & kill xxxx
ps aux | grep 6379 & kill xxxx
2. 下载官方镜像
docker pull redis:latest
3. docker preference配置file sharing - /usr/local/etc
4. 启动容器
docker run -p 6379:6379 --name myredis1 -d redis redis-server --appendonly yes
~~~

**Mac 重启后，docker container依然在，直接运行：docker start mysql1/myredis1 即可**

###  软连接的坑

~~~
touch test
ln -s test lnktest
rm lnktest #OK, 仅删除软连接
rm lnktest/ #坑, 加/后将删除软连接所指向的文件
~~~

### Java NIO + Netty + Linux 5 种 IO 模型

http://ifeve.com/java-nio-all/  <http://stor.51cto.com/art/201810/584593.htm> 

~~~
linux IO 模型：
1. 同步阻塞型：默认类型 （读写系统调用read/write阻塞直到读写完成）
2. 同步非阻塞型：设置NO_BLOCK Flag（应用程序不断轮训调用读写系统调用read/write，直到读写成功）
3. IO多路复用（异步阻塞型）：由epoll系统调用来轮训多个socket连接，其中一个socket可读或可写即可返回，然后应用程序调用回调函数进行read/write（read/write的时候是阻塞的）
4. 异步非阻塞型：linux aio，读写调用立即返回，内核读写完成后通知应用程序
5. 信号驱动 （信号值有限，网络IO中不用这种方式）

Reactor 与 Proactor模式：
两者都是基于事件驱动然后通知回调的开发模式
Reactor是轮训操作系统IO就绪（epoll），然后回调
Proactor是轮训操作系统IO读写完成（AIO），然后回调
Netty 是基于Reactor模式
~~~



### Redis缓存击穿、穿透、雪崩，数据一致性

缓存击穿：缓存当中某个key在某个时间点过期的时候，恰好在这个时间点对这个Key有大量的并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮（**单个key高并发**）

击穿解决：

1. 根据key获取value值为空时，锁上，从数据库中load数据后再释放锁。若其它线程获取锁失败，则等待一段时间后重试。

2. 使用布隆过滤器快速判断一个key是否存在于某容器中

   布隆过滤器：用于检索一个元素是否在一个集合中。它的优点是空间效率和查询时间都远远超过一般的算法，缺点是有一定的误识别率和删除困难

   [布隆过滤器](https://zh.wikipedia.org/wiki/布隆过滤器)的原理是，当一个元素被加入集合时，通过K个散列函数将这个元素映射成一个位数组中的K个点，把它们置为1。检索时，我们只要看看这些点是不是都是1就（大约）知道集合中有没有它了：如果这些点有任何一个0，则被检元素一定不在；如果都是1，则被检元素很可能在


缓存穿透：一般的缓存系统，都是按照key去缓存查询，如果不存在对应的value，就应该去后端系统查找（比如DB）。如果key对应的value是一定不存在的，并且对该key并发请求量很大，就会对后端系统造成很大的压力，同时key对应的value在DB也不存在，**DB和redis都没有找到下的高并发**，这就叫做缓存穿透

穿透解决：使用布隆过滤器在程序中进行一个拦截，找不到立即返回



缓存雪崩：是指在我们设置缓存时采用了相同的过期时间，导致缓存在某一时刻同时失效，请求全部转发到DB，DB瞬时压力过重雪崩（**多个key高并发**）

雪崩解决：

1. 加锁或用队列:让它们去进行资源竞选, 选出相应的redis client再去mysql中进行动态的操作
2. 将缓存失效时间分散开:例如在失效时间基础上增加一个随机值,避免引发集体失效事情



### 新技术

~~~
docker、k8s、etcd、FaaS（Function as a Service）
云计算核心技术：
1. 服务器虚拟化（docker）
2. 存储虚拟化（分布式文件系统Hadoop，分布式数据库HBase、NOSQL: OceanBase）
3.海量数据计算（大数据 MapReduce）、(数据采集、存储、分析、可视化)

响应式函数编程：RxJava http://reactivex.io/
~~~



### linux删除大文件前xx行

~~~
tail  -n +xx old.txt > new.txt 
mv new.txt old.txt
~~~



### 补码  

> 计算机有符号数为什么使用补码运算？
>
> 1.   补码与模
>
>    模表示运算时数字的容量，例如十进制两位数加减运算时，模为100（十进制）， 二进制两位数加减运算时，模为100（二进制），二进制8位数加减运算时，模为2 ^ 8 。
>
>    十进制两位数运算：87 - 25 = 62； 87 + （100 -25）=  162（进位1超过了模的容量，舍弃。结果一样）
>
>    二进制8位数运算： 
>
>    87 - 25 = 0101 0111 - 0001 1001 = 0011 1110 = 62；
>
>    87 + （2 ^ 8 -25）=  0101 0111 + （1 0000 0000 - 0001 1001）= 0101 0111 +  1110 0111 =1 0011 1110 = 62（进位1超过了模的容量，舍弃。结果一样）
>
>    时钟模运算（模为12）：现在在10点钟，要拨向6点钟，有两种方法：
>
>    1. 倒拨四格：10 - 4 = 6
>
>    2. 顺拨8格：10 + 8 = 18 === 6
>
>       则称8是-4对模12的补码，同理可知，9是-3对模12的补码 ...
>
>    由此可见，**模运算可以将减法用加法表示**。对于十进制模为100时，-25和（100-25）=75是一对互补的数字。对于二进制模为2 ^ 8 时，-0001 1001和1110 0111是一对互补的数字。通过这对互补的数字将减法转化为加法。
>
>    即： X - 互1 = X + 互2；（二进制当中，称 互2 为 -互1 的 补码（前提是模确定时））
>
> 2. 计算机没有减法器，只有加法器，所以必须将减法运算转为加法运算。而计算机数值存储有位数限制，超过的进位被舍弃，正符合模运算。而原码的减法运算结果 = 补码的加法运算结果。
>
> 例如： 7 - 5 = 2；
>
> 当模为2^8时，补码：正数，补码和原码相同：7补码: 0000 0111；负数，最高位为符号位，原码符号位不变，数值位取反加一即为补码：-5原码: 1 000 0101，-5补码：1 111 1011（1 0000 0000 - 0000 0101 =  1111 1011） 。
>
> 补码相加：
>
> 0000 0111 + 1111 1011 =  1 0000 0010（最高位的移位舍弃得：0000 0010: 2）
>
> 1. 使用补码可以充分利用二进制位来表达十进制的数，并且使得0的表示唯一。
>
>    计算机中有符号数的表示：最高位用来表示符号位（0为正，1位负）。如果使用原码表示，0会有两种表示方法（+0: 0 000 0000；-0:1 000 0000）。如果使用补码表示，则0的表示还是用（+0: 0 000 0000）空出来的（-0: 1 000 000）用来表示-128。因此C语言的char可表示的数值范围为-128 ～ 127。
>
>    | char二进制表示 | 对应数值 |
>    | -------------- | -------- |
>    | 0 111 1111     | 127      |
>    | 0 000 0000     | 0        |
>    | 1 000 0000     | -128     |
>    | 1 111 1111     | -1       |
>
>    | unsigned char二进制表示 | 对应数值 |
>    | ----------------------- | -------- |
>    | 0000 0000               | 0        |
>    | 1111 1111               | 255      |
>
> 2. 原码，移码，补码
>
>    移码：将每个数值加上一个偏置常数（通常编码为n位时，取偏置常数为2^n-1或（2^n-1）- 1）
>
>    计算机中：无符号数用原码表示，有符号数用补码表示，浮点数尾数用原码表示，浮点数阶码用移码表示
>
>    32位浮点数表示：\[S\]\[Exponent\]\[Significand\], 符号位：S（0: 正数，1: 负数）, 阶码（8位，移码表示，偏置常数为127），尾数部分（23位，尾数技术方法如下 ）；
>
>    尾数部分计算方法：
>    $$
>    {Significand}_2 = 110| 0000 | 0000 | 0000 | 0000 | 0000
>    $$
>
>    $$
>    Significand = 1 * 2^{-1} + 1 * 2^{-2} + 0 * 2^{-3} + 0 * 2^{-4} + ...
>    $$
>
>
>
>
>
>
>    浮点数计算方法：
> $$
>    (-1)^S * (1 + Significand) * 2^{(Exponent - 127)}
> $$
>
>
>    ![image-20181211103343830](/Users/qiaojian/Documents/learnGit/markdown/image-float-machine-code.png)



### ssh自动保活工具 - autossh使用

~~~
https://www.everythingcli.org/ssh-tunnelling-for-fun-and-profit-autossh/
~~~



### CentOs Mysql初始密码修改

~~~
1. 初始root密码
cat /var/log/mysqld.log | grep root
2. mysql -uroot -p 登录
3. set global validate_password_policy=0;
4. set global validate_password_length=4;
5. exit
6. mysql_secure_installation 修改root密码
~~~

### rsync VS scp

~~~
rsync 和 scp 都是远程同步或拷贝的命令
区别1. 只对差异文件做更新，可以做增量或全量拷贝；而scp只能做全量拷贝。
区别2. rsync不是加密传输，而scp是加密传输。
区别3. 当小文件众多的情况下，rsync会导致硬盘I/O非常高，而scp基本不影响系统正常使用
~~~

### web网络问题排查

~~~
检查本机/etc/hosts
/etc/hosts配置了IP到域名的映射

测试网络主机是否可访问（不指定端口）
ping（服务器禁ping）

pingonline(防止dns污染)

追踪到主机的传输路径：
traceroute、tracepath（不需要root）

公共域名服务器 - 谷歌8.8.8.8/8.8.4.4，阿里223.5.5.5/223.6.6.6，其他114.114.114.114/114.114.115.115

域名解析
dig、nslookup、host

查看服务器IP+端口/域名+端口通不通：
telnet 域名/IP port

查看当前运行程序
ps aux | grep app/port
ps -ef | grep app/port

查看网络连接状态
nestat -anp | grep port/app （因为服务器可能是多网卡配置，绑定地址 127.0.0.1（本机地址） 和 0.0.0.0（无限制） 区别）

查看TCP连接参数和被哪个进程使用：
ss -ltnp | grep 10001 （-p参数会打印出使用此tcp连接的进程信息（包括了进程pid））
ps -ef | grep java | grep pid

查看系统打开文件信息，-i 指定打开的端口
lsof -i :port

查看防火墙配置是否禁止访问
防火墙（Centos iptables/ Centos 7 firewall），云服务器云防火墙

Centos Selinux（关闭）:
getenforce/sestatus -v:查看selinux状态
setenforce 0:临时关闭selinux
vi /etc/selinux/config: 永久关闭， 需要重启服务器

nginx - 配置 - access log - error log

web容器 - access log （springboot application.properties配置）

请求格式合法 - URLEncode

工具 - charles

看CPU占用情况
top -c (交互模式下: P: 按CPU使用率排序；M: 按内存使用量排序)

看内存使用情况
free -m

看磁盘使用情况df -ah

看文件目录大小du -sh ./xxoo

查看系统总共运行时长和系统平均负载 uptime

实时监控系统平均负载：tload -d 1 （指定间隔1秒）
（load average: 0.00, 0.00, 0.00  // 系统平均负载，统计最近1，5，15分钟的系统平均负载，如果你的linux主机是1个双核CPU的话，当Load Average 为6的时候说明机器已经被充分使用了）

打印网络数据包进出信息：（指定tcp协议包，指定端口80）
tcpdump tcp port 80

查看用户可打开的文件描述符个数限制：（https://leokongwq.github.io/2016/11/09/linux-max-fd.html）
系统级别：
查看能打开的最大文件描述符个数限制：cat /proc/sys/fs/file-max 
设置能打开的最大文件描述符个数限制：
sysctl -w fs.file-max=xxoo(重启机器生效)
vi /etc/sysctl.conf
在文件末尾添加
fs.file-max=102400
保存退出后使用sysctl -p 命令使其生效

用户级别：
查看硬件资源限制：ulimit -Hn，设置硬件资源限制：ulimit -Hn xxoo
查看软件资源限制：ulimit -Sn，设置软件资源限制：ulimit -Sn xxoo
查看配置文件：cat /etc/security/limits.conf

~~~

### CPU 100%问题排查

~~~
1. 找出消耗cpu最高的进程PID
top -c	（显示进程运行信息列表，默认CPU使用率排序）
2. 根据PID查出消耗cpu最高的线程号
top -Hp pid （显示一个进程的线程运行信息列表，默认CPU使用率排序）
3. 导出进程快照
jstack -l pid > pid.stack
4. 根据线程号查出对应的java线程，进行处理
cat pid.stack | grep '十六进制线程号' -C 10
~~~

### Spring AOP

~~~
package: org.springframework.aop.framework;
class: DefaultAopProxyFactory
Method: createAopProxy
~~~

### ORM

~~~
两种主流模式：
1. Active Record
2. Data Mappers
~~~

### 数据库事务

~~~
1. 事务的特性：ACID
A：Atomicity 原子性，事务要么全做（commit），要么全不做（rollback）
C：Consistency 一致性
I：Isolation 隔离性，两个事务的执行互不相干
D：Durability 持久性，对数据的改变是永久的

2. 数据库的四种隔离级别
Read uncommitted：读未提交级别，会产生脏读（事务中未提交的修改，也可以被读取）
Read committed：读已提交级别，会产生不可重复读（一个事务的两次读操作中有其他事务修改了数据导致两次读到的数据不一致）
Repeated read：可重复读级别，会产生幻读（同样的条件（不一定是同一个事务中）下，两次读取到的数据不一致）
Serializable：串行化级别，可避免以上所以问题（脏读、不可重复读，幻读）

~~~

### CAP理论

~~~
C：Consistency，一致性
A：Availability，可用性
P：Partition tolerance，分区容错性

在一个分布式系统中，只能满足C、A、P其中两个特性，现实中，P是必须满足的，所以只能在C和A选择其一。
在注重用户体验的业务系统中，可用性很重要，因此分布式系统大都是： AP型+最终一致性。

BASE理论：
BA：Basic Available 基本可用
S：Soft State，同一数据的不同副本的状态，可以不需要实时一致，而是有中间状态
Eventual Consistency：最终一致性，同一数据的不同副本的状态，可以不需要实时一致，但一定要保证经过一定时间要达到最终一致性

分布式系统中不同业务场景对一致性要求不同：如交易场景要求强一致性，此时需要遵循ACID理论；如登录场景发送验证码不需要实时一致，此时遵循BASE理论即可。

分布式事务协议：
两阶段提交协议：2PC（2 phase commit）
三阶段提交协议：3PC（3 phase commit）

分布式事务解决方案：
1. 全局事务
2. 消息中间件：RocketMQ、RabbitMQ、ActiveMQ、Kafka等
3. 最大努力通知
4. TCC（Try-Confirm-Cancel）
~~~

### 并发控制

1. Linux内核并发控制

   ~~~
   	1.1 中断屏蔽
   	1.2 原子变量，原子位操作
   	1.3 自旋锁
   	1.4 信号量
   	1.5 完成量
   	1.6 互斥锁
   ~~~

2. Linux IPC 并发控制

   ~~~
   	2.1 互斥锁
   	2.2 条件变量
   ~~~

3. Java 并发包

   ~~~
   3.1 基于AQS（AbstractQueuedSynchronizer）,AQS基于Unsafe提供的CAS操作和park/unpark操作
   	3.1.1 CAS操作原理：自旋获取变量内存最新值，只有最新值和预期值一样，才更新变量的值。
   	int v;
       do{
           v = getIntVolatile(object, offset); //获取变量内存最新值
       }while(!compareAndSwapInt(object, offset, v, v+delta));//内存最新值和预期值不一样时，CAS修改失败，则继续循环获取，比较，修改，只到修改成功才跳出循环
       
       CAS使用场景：只能保证一个共享变量的原子操作
       CAS缺点：ABA问题(可使用AtomicStampedReference，通过控制变量的版本来保证CAS的正确性)，循环操作时间过长时，开销变大（资源竞争严重时，自旋循环概率增大，不适用）
   	3.1.2 park/unpark操作原理：park/unpark能够精准的对线程进行唤醒和等待，基于Linux 互斥锁和条件变量实现
   3.2 	
   ~~~

   

### Netty tcp backlog 参数

~~~txt
参考： https://www.jianshu.com/p/e6f2036621f4

内核会根据/proc/sys/net/core/somaxconn和backlog的较小值设置accept queue的大小，如果想扩大accept queue的大小，必须要同时调整这两个参数

~~~

### JVM FullGC 参数 MetaspaceSize + MaxMetaspaceSize

~~~
参考： https://www.jianshu.com/p/b448c21d2e71

MetaspaceSize：触发FullGC的阈值

jstat -gc pid
jstat -gc pid 2s 3 (2s统计一次，一共统计3次)
jinfo -flag MetaspaceSize pid（查看某个java进程的jvm参数MetaspaceSize）

建议：
MetaspaceSize和MaxMetaspaceSize设置一样大；
具体设置多大，建议稳定运行一段时间后通过jstat -gc pid确认且这个值大一些，对于大部分项目256m即可
~~~

### JVM ReservedCodeCacheSize 参数

~~~
参考：https://juejin.im/post/5aebf997f265da0ba76f99db

jinfo -flag ReservedCodeCacheSize pid（查看某个java进程的jvm参数ReservedCodeCacheSize）

~~~

### Java 日志系统

~~~
参考 https://zhuanlan.zhihu.com/p/24272450
1. 刚开始： 第三方日志系统：log4j等
2. JDK自带log： JUL（Java Util Log）加入
3. 日志门面JCL（Java Common Logging）问世，其他日志实现自己桥接到JCL
4. 日志门面SLF4J问世，加上自带日志实现Logback，其他日志实现自己桥接到SLF4J
5. Log4j2问世，自带日志门面log4j2-api，加上日志实现log4j2-core

至此，日志门面有三个了：JCL、SLF4J、log4j2-api，日志实现有4个：JUL、log4j、logback、log4j2-core

一个字：乱

实际项目中使用日志，应该遵循以下规则：
1. 总是使用日志门面
2. 只添加一个日志实现的依赖
3. 使用第三方库，有必要排出第三方库中的日志实现依赖

Spring-boot项目默认使用：SLF4J + logback

~~~



Netty特性：异步 + 事件驱动，底层：Java NIO（Linux AIO + epoll）





CAS， ACCID，反射原理，ORM原理



https://www.imooc.com/course/programdetail/pid/59

https://www.imooc.com/course/programdetail/pid/31

https://www.jianshu.com/p/b30955885e6d

http://dockone.io/article/932

https://github.com/tmrts/go-patterns

http://fangjian0423.github.io/2017/04/30/springboot-startup-analysis/

https://www.jianshu.com/p/1a9fd8936bd8

https://github.com/JeffLi1993/springboot-learning-example

https://docs.spring.io/spring-boot/docs/current-SNAPSHOT/reference/htmlsingle/#spring-boot-starter-logging

http://www.runoob.com/redis/redis-backup.html

https://yeasy.gitbooks.io/docker_practice/image/build.html

https://github.com/jiayisheji/blog/issues/16

https://wizardforcel.gitbooks.io/100-gdb-tips/print-large-array.html

http://www.icourse163.org/learn/NJU-1001625001?tid=1003072006#/learn/announce

https://github.com/lenve/JavaEETest



spacelauncher 

open . & cdto

zsh 自动提示git

set -o vi - 命令行vi模式

set -o emacs - 退出命令行vi模式



